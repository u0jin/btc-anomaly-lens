from datetime import datetime
from collections import Counter
import numpy as np
import pandas as pd  # âœ… ì´ê±° ë°˜ë“œì‹œ ì¶”ê°€
import os
import streamlit as st # ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥ìš©

# 1. ê±°ë˜ ê°„ê²© ì´ìƒ íƒì§€ (60ì´ˆ ë¯¸ë§Œ)
def interval_anomaly_score(tx_list):
    if len(tx_list) < 2:
        return 0, []
    try:
        timestamps = [
            datetime.fromisoformat(tx['timestamp'])
            for tx in tx_list
            if isinstance(tx, dict) and 'timestamp' in tx
        ]
    except Exception:
        return 0, []
    
    if len(timestamps) < 2:
        return 0, []

    intervals = [
        (t2 - t1).total_seconds()
        for t1, t2 in zip(timestamps[:-1], timestamps[1:])
    ]
    short_intervals = [i for i in intervals if i < 60]
    score = min(25, len(short_intervals) * 5)
    return score, short_intervals


# 2. ì´ìƒ ê¸ˆì•¡ íƒì§€ (IQR ì´ìƒ)
def amount_anomaly_score(tx_list):
    values = [tx['amount'] for tx in tx_list if isinstance(tx, dict) and 'amount' in tx]
    if not values:
        return 0, []

    df = pd.DataFrame(values, columns=['amount'])
    q1 = df['amount'].quantile(0.25)
    q3 = df['amount'].quantile(0.75)
    iqr = q3 - q1
    threshold = q3 + 1.5 * iqr
    outliers = df[df['amount'] > threshold]['amount'].tolist()

    score = min(len(outliers) * 5, 25)
    return score, outliers

# 3. ë™ì¼ ìˆ˜ì‹  ì£¼ì†Œ ë°˜ë³µ íƒì§€
def repeated_address_score(tx_list):
    targets = [tx.get('to') for tx in tx_list if isinstance(tx, dict) and tx.get('to')]

    counter = Counter(targets)
    flagged = [addr for addr, count in counter.items() if count >= 3]
    score = min(25, len(flagged) * 5)
    return score, flagged

# 4. ì‹œê³„ì—´ ìƒ ì´ìƒ ê°„ê²© íƒì§€
def time_gap_anomaly_score(tx_list):
    if len(tx_list) < 2:
        return 0, []
    try:
        timestamps = [datetime.fromisoformat(tx['timestamp']) for tx in tx_list]
    except Exception:
        return 0, []
    gaps = [
        (t2 - t1).total_seconds()
        for t1, t2 in zip(timestamps[:-1], timestamps[1:])
    ]
    abnormal = [g for g in gaps if g < 10 or g > 3600]
    score = min(15, len(abnormal) * 5)
    return score, abnormal

# 5. ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë”© ë° íƒì§€
def load_blacklist():
    try:
        current_dir = os.path.dirname(__file__)
        blacklist_path = os.path.join(current_dir, "..", "data", "blacklist.txt")

        if not os.path.exists(blacklist_path):
            st.error(f"âŒ blacklist.txt not found at: {blacklist_path}")
            return set()

        with open(blacklist_path, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f if line.strip())
    except Exception as e:
        st.markdown(f"âš ï¸ **ë¸”ë™ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì˜¤ë¥˜: {e}**")
        return set()

def load_mixer_addresses():
    """ë¯¹ì„œ ì£¼ì†Œë“¤ì„ ì—¬ëŸ¬ íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        current_dir = os.path.dirname(__file__)
        data_dir = os.path.join(current_dir, "..", "data")
        
        mixer_files = [
            "mixer_addresses.txt",      # Wasabi
            "samourai_mixer.txt",       # Samourai
            "joinmarket_mixer.txt",     # JoinMarket
            "other_mixers.txt"          # ê¸°íƒ€ ë¯¹ì„œë“¤
        ]
        
        mixer_addresses = {}
        
        for filename in mixer_files:
            file_path = os.path.join(data_dir, filename)
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            parts = line.split(',')
                            if len(parts) >= 3:
                                address = parts[0].strip()
                                mixer_type = parts[1].strip()
                                source = parts[3].strip() if len(parts) > 3 else "Unknown"
                                mixer_addresses[address] = f"{mixer_type} ({source})"
            else:
                st.markdown(f"âš ï¸ **{filename} not found at: {file_path}**")
        
        return mixer_addresses
    except Exception as e:
        st.markdown(f"âš ï¸ **ë¯¹ì„œ ì£¼ì†Œ íŒŒì¼ ì˜¤ë¥˜: {e}**")
        return {}

def load_bridge_addresses():
    """ë¸Œë¦¿ì§€ ì£¼ì†Œë“¤ì„ ì—¬ëŸ¬ íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        current_dir = os.path.dirname(__file__)
        data_dir = os.path.join(current_dir, "..", "data")
        
        bridge_files = [
            "wbtc_bridge.txt",          # WBTC
            "renvm_bridge.txt",         # RenVM
            "multichain_bridge.txt",    # Multichain
            "binance_bridge.txt",       # Binance
            "coinbase_bridge.txt",      # Coinbase
            "other_bridges.txt"         # ê¸°íƒ€ ë¸Œë¦¿ì§€ë“¤
        ]
        
        bridge_addresses = {}
        
        for filename in bridge_files:
            file_path = os.path.join(data_dir, filename)
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            parts = line.split(',')
                            if len(parts) >= 3:
                                address = parts[0].strip()
                                bridge_type = parts[1].strip()
                                source = parts[3].strip() if len(parts) > 3 else "Unknown"
                                bridge_addresses[address] = f"{bridge_type} ({source})"
            else:
                st.markdown(f"âš ï¸ **{filename} not found at: {file_path}**")
        
        return bridge_addresses
    except Exception as e:
        st.markdown(f"âš ï¸ **ë¸Œë¦¿ì§€ ì£¼ì†Œ íŒŒì¼ ì˜¤ë¥˜: {e}**")
        return {}

def load_exchange_addresses():
    """ê±°ë˜ì†Œ ì£¼ì†Œë“¤ì„ íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        current_dir = os.path.dirname(__file__)
        # ì‹¤ì œ ê±°ë˜ì†Œ ì£¼ì†Œ íŒŒì¼ ìš°ì„  ì‚¬ìš©
        exchange_path = os.path.join(current_dir, "..", "data", "real_exchange_addresses.txt")
        if not os.path.exists(exchange_path):
            # ê¸°ì¡´ íŒŒì¼ë¡œ í´ë°±
            exchange_path = os.path.join(current_dir, "..", "data", "exchange_addresses.txt")
            if not os.path.exists(exchange_path):
                st.markdown(f"âš ï¸ **ê±°ë˜ì†Œ ì£¼ì†Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exchange_path}**")
                return {}
        
        exchange_addresses = {}
        with open(exchange_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    parts = line.split(',')
                    if len(parts) >= 3:
                        address = parts[0].strip()
                        exch_name = parts[1].strip()
                        address_type = parts[2].strip() if len(parts) > 2 else "Unknown"
                        features = parts[3].strip() if len(parts) > 3 else "Unknown"
                        source = parts[4].strip() if len(parts) > 4 else "Unknown"
                        exchange_addresses[address] = f"{exch_name} ({address_type}, {features}, {source})"
        return exchange_addresses
    except Exception as e:
        st.markdown(f"âš ï¸ **ê±°ë˜ì†Œ ì£¼ì†Œ íŒŒì¼ ì˜¤ë¥˜: {e}**")
        return {}

def exchange_detection_score(tx_list, address=None):
    """ê±°ë˜ì†Œ ì£¼ì†Œì™€ ì—°ê²°ëœ ì…ì¶œê¸ˆ ì—¬ë¶€ íƒì§€ + íŒ¨í„´ ë¶„ì„"""
    exchange_addresses = load_exchange_addresses()
    exchange_hits = set()
    exchange_details = {}
    
    # ê±°ë˜ì†Œ ì£¼ì†Œ ë¡œë“œ ì™„ë£Œ (ë””ë²„ê¹… ë©”ì‹œì§€ ì œê±°)
    
    for tx in tx_list:
        to_address = tx.get('to', '')
        from_address = tx.get('from', '')
        amount = tx.get('amount', 0)
        
        # ì…ê¸ˆ (ê±°ë˜ì†Œë¡œì˜ ì „ì†¡)
        if to_address in exchange_addresses:
            exchange_name = exchange_addresses[to_address].split(' (')[0]  # ê±°ë˜ì†Œëª…ë§Œ ì¶”ì¶œ
            exchange_hits.add(exchange_name)
            if exchange_name not in exchange_details:
                exchange_details[exchange_name] = {'deposits': [], 'withdrawals': []}
            exchange_details[exchange_name]['deposits'].append({
                'address': to_address,
                'amount': amount,
                'type': exchange_addresses[to_address]
            })
        
        # ì¶œê¸ˆ (ê±°ë˜ì†Œì—ì„œì˜ ì „ì†¡)
        if from_address in exchange_addresses:
            exchange_name = exchange_addresses[from_address].split(' (')[0]  # ê±°ë˜ì†Œëª…ë§Œ ì¶”ì¶œ
            exchange_hits.add(exchange_name)
            if exchange_name not in exchange_details:
                exchange_details[exchange_name] = {'deposits': [], 'withdrawals': []}
            exchange_details[exchange_name]['withdrawals'].append({
                'address': from_address,
                'amount': amount,
                'type': exchange_addresses[from_address]
            })
    
    # íŒ¨í„´ ë¶„ì„ - íŠ¸ëœì­ì…˜ ë£¨í”„ ë°–ìœ¼ë¡œ ì´ë™
    pattern_analysis = {}
    if tx_list:
        try:
            from logic.exchange_pattern_analyzer import analyze_exchange_patterns
            from logic.exchange_identifier import identify_exchange_comprehensive
            
            # ê¸°ì¡´ íŒ¨í„´ ë¶„ì„
            pattern_analysis = analyze_exchange_patterns(tx_list)
            
            # ì¢…í•© ê±°ë˜ì†Œ ì‹ë³„ ì‹œìŠ¤í…œ
            comprehensive_result = identify_exchange_comprehensive(address, tx_list) if address else None
            final_result = comprehensive_result['final_result'] if comprehensive_result else {}
            final_exchange = final_result.get('exchange', None)
            final_confidence = final_result.get('confidence', 'low')
            final_method = final_result.get('method', '-')
            description = final_result.get('description', '')
            cross_validation = comprehensive_result.get('cross_validation', {}) if comprehensive_result else {}
            methods_used = comprehensive_result.get('methods_used', []) if comprehensive_result else []
            # ë‹¨ê³„ë³„ ì„±ê³µ/ì‹¤íŒ¨
            public_db_result = comprehensive_result.get('public_db', {}) if comprehensive_result else {}
            pattern_result = comprehensive_result.get('pattern_analysis', {}) if comprehensive_result else {}
            official_result = comprehensive_result.get('official_address', {}) if comprehensive_result else {}
            cluster_result = comprehensive_result.get('cluster_analysis', {}) if comprehensive_result else {}
            
            # ê±°ë˜ì†Œ ì¸ì‹ ê²°ê³¼ëŠ” app.pyì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°
            
            # 2. ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© ìŠ¤í…ë°” (ê°€ë¡œ í–‰)
            steps = [
                ("ê³µê°œ DB", public_db_result.get('found', False), "ğŸŒ"),
                ("íŒ¨í„´ ë¶„ì„", pattern_result.get('confidence', 'low') != 'low', "ğŸ“ˆ"),
                ("ê³µì‹ ì£¼ì†Œ", official_result.get('found', False), "ğŸ›ï¸"),
                ("í´ëŸ¬ìŠ¤í„°", cluster_result.get('confidence', 'low') == 'high', "ğŸ”—"),
            ]
            
            # ê°€ë¡œ í–‰ìœ¼ë¡œ í‘œì‹œ
            cols = st.columns(len(steps))
            for i, (name, success, icon) in enumerate(steps):
                with cols[i]:
                    color = "#08BDBD" if success else "#ccc"
                    status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
                    st.markdown(f"""
                    <div style='text-align: center; padding: 12px; border: 2px solid {color}; border-radius: 8px; background: {color}22;'>
                        <div style='font-size: 28px; color: {color}; margin-bottom: 8px;'>{icon}</div>
                        <div style='font-size: 16px; color: {color}; font-weight: bold; margin-bottom: 4px;'>{name}</div>
                        <div style='font-size: 14px; color: {color};'>{status}</div>
                    </div>
                    """, unsafe_allow_html=True)
            
            # 3. êµì°¨ ê²€ì¦/ì„¸ë¶€ ì •ë³´ëŠ” í† ê¸€(expander)ë¡œ
            with st.expander("ğŸ”¬ êµì°¨ ê²€ì¦ ìƒì„¸ ë³´ê¸°", expanded=False):
                st.markdown(f"""
                <ul>
                    <li>ê²€ì¦ ì ìˆ˜: <b>{cross_validation.get('validation_score', 0)}/{cross_validation.get('total_methods', 0)}</b></li>
                    <li>ê²€ì¦ ë¹„ìœ¨: <b>{cross_validation.get('cross_validation_ratio', 0):.1%}</b></li>
                    <li>ìµœì¢… ì‹ ë¢°ë„: <b>{cross_validation.get('final_confidence', 'low')}</b></li>
                </ul>
                """, unsafe_allow_html=True)
                if methods_used:
                    st.markdown(f"**ğŸ“‹ ì‚¬ìš©ëœ ì‹ë³„ ë°©ë²•:**")
                    for method in methods_used:
                        method_names = {
                            'public_database': 'ê³µê°œ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰',
                            'pattern_analysis': 'ê±°ë˜ íŒ¨í„´ ë¶„ì„',
                            'official_address': 'ê³µì‹ ì£¼ì†Œ í™•ì¸',
                            'cluster_analysis': 'ì§€ê°‘ í´ëŸ¬ìŠ¤í„° ë¶„ì„'
                        }
                        st.caption(f"â€¢ {method_names.get(method, method)}")
        
        except Exception as e:
            st.markdown(f"âš ï¸ **íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}**")
    
    # ìƒì„¸ ì •ë³´ì™€ íŒ¨í„´ ë¶„ì„ì„ í•¨ê»˜ ë°˜í™˜
    return list(exchange_hits), exchange_details, pattern_analysis

def blacklist_score(tx_list):
    blacklist = load_blacklist()
    involved = [tx.get('to') for tx in tx_list if isinstance(tx, dict) and tx.get('to') in blacklist]
    if involved:
        return True, 100  # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì£¼ì†Œê°€ í¬í•¨ë˜ë©´ 100ì 
    return False, 0

# 6. Mixer íƒì§€ ê¸°ëŠ¥
def mixer_detection_score(tx_list):
    """
    ë¯¹ì„œ(Mixer) ì‚¬ìš© ì—¬ë¶€ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    - Wasabi, Samourai, JoinMarket ë“±ì˜ íŠ¹ì§•ì ì¸ íŒ¨í„´ íƒì§€
    - ë‹¤ì¤‘ ì…ë ¥/ì¶œë ¥, ë™ì¼ ê¸ˆì•¡, ì‹œê°„ ê°„ê²© íŒ¨í„´ ë¶„ì„
    """
    mixer_indicators = []
    mixer_score = 0
    
    if not tx_list:
        return mixer_score, mixer_indicators
    
    # 1. ì•Œë ¤ì§„ ë¯¹ì„œ ì£¼ì†Œ ë§¤ì¹­
    known_mixer_addresses = load_mixer_addresses()
    mixer_hits = set()
    for tx in tx_list:
        to_address = tx.get('to', '')
        if to_address in known_mixer_addresses:
            mixer_hits.add(known_mixer_addresses[to_address])
    
    if mixer_hits:
        mixer_score += min(25, len(mixer_hits) * 10)
        for mixer_type in mixer_hits:
            mixer_indicators.append(f"ì•Œë ¤ì§„ ë¯¹ì„œ ì£¼ì†Œ: {mixer_type}")
    
    # 2. ë‹¤ì¤‘ ì…ë ¥/ì¶œë ¥ íŒ¨í„´ íƒì§€
    multi_io_count = 0
    for tx in tx_list:
        inputs = tx.get('inputs', [])
        outputs = tx.get('outputs', [])
        
        if len(inputs) > 3 and len(outputs) > 3:
            multi_io_count += 1
    
    if multi_io_count > 0:
        mixer_score += min(20, multi_io_count * 5)
        mixer_indicators.append(f"ë‹¤ì¤‘ I/O íŒ¨í„´: {multi_io_count}ê°œ íŠ¸ëœì­ì…˜")
    
    # 2. ë™ì¼ ê¸ˆì•¡ íŒ¨í„´ íƒì§€ (ë¯¹ì„œì˜ íŠ¹ì§•)
    amounts = [tx.get('amount', 0) for tx in tx_list]
    amount_counter = Counter(amounts)
    repeated_amounts = [amt for amt, count in amount_counter.items() if count >= 2 and amt > 0]
    
    if repeated_amounts:
        mixer_score += min(15, len(repeated_amounts) * 3)
        mixer_indicators.append(f"ë™ì¼ ê¸ˆì•¡ íŒ¨í„´: {len(repeated_amounts)}ê°œ ì¤‘ë³µ ê¸ˆì•¡")
    
    # 3. ì‹œê°„ ê°„ê²© íŒ¨í„´ ë¶„ì„ (ë¯¹ì„œëŠ” ë³´í†µ ì§§ì€ ê°„ê²©ìœ¼ë¡œ ì—°ì† íŠ¸ëœì­ì…˜)
    try:
        timestamps = [datetime.fromisoformat(tx['timestamp']) for tx in tx_list if 'timestamp' in tx]
        if len(timestamps) >= 2:
            intervals = [(t2 - t1).total_seconds() for t1, t2 in zip(timestamps[:-1], timestamps[1:])]
            short_intervals = [i for i in intervals if i < 30]  # 30ì´ˆ ì´ë‚´ ê°„ê²©
            
            if len(short_intervals) > len(intervals) * 0.5:  # 50% ì´ìƒì´ ì§§ì€ ê°„ê²©
                mixer_score += 10
                mixer_indicators.append("ë¹ ë¥¸ ì—°ì† íŠ¸ëœì­ì…˜ íŒ¨í„´")
    except Exception:
        pass
    
    return mixer_score, mixer_indicators

# 7. Cross-chain Bridge íƒì§€ ê¸°ëŠ¥
def cross_chain_detection_score(tx_list):
    """
    í¬ë¡œìŠ¤ì²´ì¸ ë¸Œë¦¿ì§€ ì‚¬ìš© ì—¬ë¶€ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    - ì£¼ìš” ë¸Œë¦¿ì§€ ì£¼ì†Œ íŒ¨í„´ íƒì§€
    - ëŒ€ìš©ëŸ‰ ë‹¨ì¼ íŠ¸ëœì­ì…˜ íƒì§€
    - íŠ¹ì • ë¸Œë¦¿ì§€ ì„œë¹„ìŠ¤ ì£¼ì†Œ ë§¤ì¹­
    """
    bridge_indicators = []
    bridge_score = 0
    
    if not tx_list:
        return bridge_score, bridge_indicators
    
    # 1. ë¸Œë¦¿ì§€ ì£¼ì†Œ ë§¤ì¹­
    bridge_addresses = load_bridge_addresses()
    bridge_hits = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©
    for tx in tx_list:
        to_address = tx.get('to', '')
        if to_address in bridge_addresses:
            bridge_hits.add(bridge_addresses[to_address])
    
    if bridge_hits:
        bridge_score += min(30, len(bridge_hits) * 10)
        for bridge_type in bridge_hits:
            bridge_indicators.append(f"ë¸Œë¦¿ì§€ ì£¼ì†Œ ê°ì§€: {bridge_type}")
    
    # 2. ëŒ€ìš©ëŸ‰ ë‹¨ì¼ íŠ¸ëœì­ì…˜ íƒì§€ (ë¸Œë¦¿ì§€ íŠ¹ì§•)
    large_txs = [tx for tx in tx_list if tx.get('amount', 0) > 1000000]  # 1 BTC ì´ìƒ
    if large_txs:
        bridge_score += min(20, len(large_txs) * 5)
        bridge_indicators.append(f"ëŒ€ìš©ëŸ‰ íŠ¸ëœì­ì…˜: {len(large_txs)}ê°œ")
    
    # 3. íŠ¹ì • íŒ¨í„´ íƒì§€ (ë¸Œë¦¿ì§€ ì‚¬ìš© ì‹œ íŠ¹ì§•ì ì¸ íŒ¨í„´)
    # - í° ê¸ˆì•¡ì˜ ë‹¨ì¼ íŠ¸ëœì­ì…˜ í›„ ì‘ì€ ê¸ˆì•¡ì˜ ë¶„ì‚°
    amounts = [tx.get('amount', 0) for tx in tx_list]
    if amounts:
        max_amount = max(amounts)
        if max_amount > 500000:  # 0.5 BTC ì´ìƒ
            small_txs = [amt for amt in amounts if 0 < amt < max_amount * 0.1]
            if len(small_txs) >= 2:
                bridge_score += 15
                bridge_indicators.append("ë¸Œë¦¿ì§€ í›„ ë¶„ì‚° íŒ¨í„´ ê°ì§€")
    
    return bridge_score, bridge_indicators

# 8. í†µí•© ì„¸íƒ ì˜ì‹¬ë„ ë¶„ì„
def money_laundering_risk_score(tx_list):
    """
    ì „ì²´ì ì¸ ì„¸íƒ ì˜ì‹¬ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    risk_indicators = []
    total_risk_score = 0
    
    # ê° íƒì§€ ê¸°ëŠ¥ ì‹¤í–‰
    mixer_score, mixer_indicators = mixer_detection_score(tx_list)
    bridge_score, bridge_indicators = cross_chain_detection_score(tx_list)
    
    total_risk_score = mixer_score + bridge_score
    
    # ì§€í‘œë“¤ í†µí•©
    risk_indicators.extend(mixer_indicators)
    risk_indicators.extend(bridge_indicators)
    
    # ì¶”ê°€ ìœ„í—˜ ì§€í‘œ
    if len(tx_list) > 10:
        risk_indicators.append("ë†’ì€ íŠ¸ëœì­ì…˜ ë³¼ë¥¨")
        total_risk_score += 10
    
    # ê¸ˆì•¡ ë¶„ì‚° íŒ¨í„´
    amounts = [tx.get('amount', 0) for tx in tx_list]
    if amounts:
        amount_variance = np.var(amounts) if len(amounts) > 1 else 0
        if amount_variance > 1000000:  # ë†’ì€ ë¶„ì‚°
            risk_indicators.append("ë¶ˆê·œì¹™í•œ ê¸ˆì•¡ ë¶„ì‚° íŒ¨í„´")
            total_risk_score += 15
    
    return total_risk_score, risk_indicators
